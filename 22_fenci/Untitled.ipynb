{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文分词原理和实现 - 狮子座明仔知识集散场 - CSDN博客\n",
    "https://blog.csdn.net/mingzai624/article/details/51698643\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# coding:utf-8\n",
    "\n",
    "# from lm import LanguageModel\n",
    "from nltk.lm.api import LanguageModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node(object):\n",
    "  \"\"\"有向图中的节点\"\"\"\n",
    "  def __init__(self,word):\n",
    "    # 当前节点作为左右路径中的节点时的得分\n",
    "    self.max_score = 0.0\n",
    "    # 前一个最优节点\n",
    "    self.prev_node = None\n",
    "    # 当前节点所代表的词\n",
    "    self.word = word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "  \"\"\"有向图\"\"\"\n",
    "  def __init__(self):\n",
    "    # 有向图中的序列是一组hash集合\n",
    "    self.sequence = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPSplit(object):\n",
    "    \n",
    "  \"\"\"动态规划分词\"\"\"\n",
    "  def __init__(self):\n",
    "    self.lm = LanguageModel('RenMinData.txt')\n",
    "    self.dict = {}\n",
    "    self.words = []\n",
    "    self.max_len_word = 0\n",
    "    self.load_dict('dict.txt')\n",
    "    self.graph = None\n",
    "    self.viterbi_cache = {}\n",
    "    \n",
    "  def get_key(self, t, k):\n",
    "    return '_'.join([str(t),str(k)])\n",
    "\n",
    "  def load_dict(self,file):\n",
    "    with open(file, 'r') as f:\n",
    "      for line in f:\n",
    "        word_list = [w.encode('utf-8') for w in list(line.strip().decode('utf-8'))]\n",
    "        if len(word_list) > 0:\n",
    "          self.dict[''.join(word_list)] = 1\n",
    "          if len(word_list) > self.max_len_word:\n",
    "            self.max_len_word = len(word_list)\n",
    "            \n",
    "  def createGraph(self):\n",
    "    \"\"\"根据输入的句子创建有向图\"\"\"\n",
    "    self.graph = Graph()\n",
    "    for i in range(len(self.words)):\n",
    "      self.graph.sequence.append({})\n",
    "    word_length = len(self.words)\n",
    "    # 为每一个字所在的位置创建一个可能词集合\n",
    "    for i in range(word_length):\n",
    "      for j in range(self.max_len_word):\n",
    "        if i+j+1 > len(self.words):\n",
    "          break\n",
    "        word = ''.join(self.words[i:i+j+1])\n",
    "        if word in self.dict:\n",
    "          node = Node(word)\n",
    "          # 按照该词的结尾字为其分配位置\n",
    "          self.graph.sequence[i+j][word] = node\n",
    "    # 增加一个结束空节点，方便计算\n",
    "    end = Node('#')\n",
    "    self.graph.sequence.append({'#':end})\n",
    "    # for s in self.graph.sequence:\n",
    "    #   for i in s.values():\n",
    "    #     print i.word,\n",
    "    #   print ' - '\n",
    "    # exit(-1)\n",
    "    \n",
    "  def split(self, sentence):\n",
    "    self.words = [w.encode('utf-8') for w in list(sentence.decode('utf-8'))]\n",
    "    self.createGraph()\n",
    "    # 根据viterbi动态规划算法计算图中的所有节点最大分数\n",
    "    self.viterbi(len(self.words), '#')\n",
    "    # 输出分支最大的节点\n",
    "    end = self.graph.sequence[-1]['#']\n",
    "    node = end.prev_node\n",
    "    result = []\n",
    "    while node:\n",
    "      result.insert(0,node.word)\n",
    "      node = node.prev_node\n",
    "    print( ' '.join(self.words))\n",
    "    print( ' '.join(result))\n",
    "    \n",
    "  def viterbi(self, t, k):\n",
    "    \"\"\"第t个位置，是单词k的最优路径概率\"\"\"\n",
    "    if self.get_key(t,k) in self.viterbi_cache:\n",
    "      return self.viterbi_cache[self.get_key(t,k)]\n",
    "    node = self.graph.sequence[t][k]\n",
    "    # t = 0 的情况,即句子第一个字\n",
    "    if t == 0:\n",
    "      node.max_score = self.lm.get_init_prop(k)\n",
    "      self.viterbi_cache[self.get_key(t,k)] = node.max_score\n",
    "      return node.max_score\n",
    "    prev_t = t - len(k.decode('utf-8'))\n",
    "    # 当前一个节点的位置已经超出句首，则无需再计算概率\n",
    "    if prev_t == -1:\n",
    "      return 1.0\n",
    "    # 获得前一个状态所有可能的汉字\n",
    "    pre_words = self.graph.sequence[prev_t].keys()\n",
    "    for l in pre_words:\n",
    "      # 从l到k的状态转移概率\n",
    "      state_transfer = self.lm.get_trans_prop(k, l)\n",
    "      # 当前状态的得分为上一个最优路径的概率乘以当前的状态转移概率\n",
    "      score = self.viterbi(prev_t, l) * state_transfer\n",
    "      prev_node = self.graph.sequence[prev_t][l]\n",
    "      cur_score = score + prev_node.max_score\n",
    "      if cur_score > node.max_score:\n",
    "        node.max_score = cur_score\n",
    "        # 把当前节点的上一最优节点保存起来，用来回溯输出\n",
    "        node.prev_node = self.graph.sequence[prev_t][l]\n",
    "    self.viterbi_cache[self.get_key(t,k)] = node.max_score\n",
    "    return node.max_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  dp = DPSplit()\n",
    "  dp.split('中国人民银行')\n",
    "  dp.split('中华人民共和国今天成立了')\n",
    "  dp.split('努力提高居民收入')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class LanguageModel with abstract methods unmasked_score",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-174f78df48e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-6028d803d61f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDPSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'中国人民银行'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'中华人民共和国今天成立了'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'努力提高居民收入'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-170c1c8f5971>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;34m\"\"\"动态规划分词\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RenMinData.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class LanguageModel with abstract methods unmasked_score"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
